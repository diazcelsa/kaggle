{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competiton | Telstra Network Disruptions\n",
    "\n",
    ">We evaluate which parameters of Random Forest classifier provide the best score.\n",
    "\n",
    ">The prediction is performed through Grid Search. Two datasets are generated in each run and two parameters are evaluated each time.\n",
    "\n",
    ">The mean score between the two datasets is displayed in a heatmap.\n",
    "\n",
    ">The choosen parameters will be used in run_predict.py for final prediction.\n",
    "\n",
    "Go to the official page of the [Kaggle Competition.](https://www.kaggle.com/c/telstra-recruiting-network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal for this Notebook:\n",
    "* Generate and evaluate predictions through Grid Search\n",
    "* Compare scores obtained for Random Forest classifier parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series, DataFrame\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import grid_search\n",
    "from scipy import stats\n",
    "from data_modifier import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Handle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Load, Clean, Aggregate and Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event = pd.read_csv(\"../../../github_data/telstradisr_data/event_type.csv\")\n",
    "log = pd.read_csv(\"../../../github_data/telstradisr_data/log_feature.csv\")\n",
    "sample = pd.read_csv(\"../../../github_data/telstradisr_data/sample_submission.csv\")\n",
    "severity = pd.read_csv(\"../../../github_data/telstradisr_data/severity_type.csv\")\n",
    "resource = pd.read_csv(\"../../../github_data/telstradisr_data/resource_type.csv\")\n",
    "train = pd.read_csv(\"../../../github_data/telstradisr_data/train.csv\")\n",
    "test = pd.read_csv(\"../../../github_data/telstradisr_data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event['event_type'] = event['event_type'].str.split(' ').str[1]\n",
    "log['log_feature'] = log['log_feature'].str.split(' ').str[1]\n",
    "severity['severity_type'] = severity['severity_type'].str.split(' ').str[1]\n",
    "resource['resource_type'] = resource['resource_type'].str.split(' ').str[1]\n",
    "test['location'] = test['location'].str.split(' ').str[1]\n",
    "train['location'] = train['location'].str.split(' ').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tables = [log,event,severity,resource] \n",
    "names = ['log','event','severity','resource'] \n",
    "for i in range(len(tables)):\n",
    "    check = unique_column(tables[i],tables[i].columns[-1])\n",
    "    \n",
    "    # AGGREGATE CATEGORICAL VALUES INTO A DICTIO\n",
    "    if check == False:\n",
    "        if len(tables[i].columns) == 2:\n",
    "            a = tables[i].groupby([tables[i].columns[-2],tables[i].columns[-1]]).agg({tables[i].columns[-1]:'count'})\n",
    "            a.index.names = ['id','cat']\n",
    "            a = a.reset_index()\n",
    "            a = a.set_index('cat')\n",
    "                    \n",
    "            # take care that keys are still integers in the dict            \n",
    "            a = a.groupby('id').apply(lambda x: {int(k):int(v) for k,v in x.to_dict()[tables[i].columns[-1]].items()})\n",
    "            tables[i] = pd.DataFrame(a,columns=[tables[i].columns[-1]])\n",
    "            \n",
    "        elif len(tables[i].columns) == 3:\n",
    "            a = tables[i].groupby([tables[i].columns[-3],tables[i].columns[-2],tables[i].columns[-1]]).agg({tables[i].columns[-1]:'count',tables[i].columns[-2]:'count'})\n",
    "            a.index.names = ['id','cat1','cat2']\n",
    "            a = a.reset_index()\n",
    "            a = a.set_index('cat1')\n",
    "            b = a.set_index('cat2')\n",
    "            \n",
    "            # take care that keys are still integers in the dict\n",
    "            a = a.groupby('id').apply(lambda x: {int(k):int(v) for k,v in x.to_dict()[tables[i].columns[-1]].items()})\n",
    "            b = b.groupby('id').apply(lambda x: {int(k):int(v) for k,v in x.to_dict()[tables[i].columns[-2]].items()})\n",
    "            log1 = pd.DataFrame(a,columns=[tables[i].columns[-1]])\n",
    "            log2 = pd.DataFrame(b,columns=[tables[i].columns[-2]])\n",
    "event = tables[1]\n",
    "severity = tables[2]\n",
    "resource = tables[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.merge(event, left_on='id', right_index=True, how='left')\n",
    "train = train.merge(severity, left_on='id', right_index=True, how='left')\n",
    "train = train.merge(resource, left_on='id', right_index=True, how='left')\n",
    "train = train.merge(log1, left_on='id', right_index=True, how='left')\n",
    "train = train.merge(log2, left_on='id', right_index=True, how='left')\n",
    "train = train[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_a, te_a = train_test_split(train, train_size = 0.8)\n",
    "y_train = tr_a.fault_severity\n",
    "y_test = te_a.fault_severity\n",
    "tr_a.drop(tr_a.columns[[0,2]], axis=1, inplace=True)\n",
    "te_a.drop(te_a.columns[[0,2]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predict with different combination of Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid_1 =  {'randomforestclassifier__max_depth': [8,16],\n",
    "               'randomforestclassifier__criterion': ['gini'], \n",
    "               'randomforestclassifier__n_estimators':[5,20], \n",
    "               'randomforestclassifier__max_leaf_nodes':[None], \n",
    "               'randomforestclassifier__min_samples_split':[2],\n",
    "               'randomforestclassifier__min_samples_leaf':[10], \n",
    "               'randomforestclassifier__min_weight_fraction_leaf':[0.0],\n",
    "               'randomforestclassifier__n_jobs':[1]\n",
    "}\n",
    "param_grid_2 =  {'randomforestclassifier__max_depth': [4,8],\n",
    "               'randomforestclassifier__criterion': ['gini'], \n",
    "               'randomforestclassifier__n_estimators':[5], \n",
    "               'randomforestclassifier__max_leaf_nodes':[None], \n",
    "               'randomforestclassifier__min_samples_split':[2],\n",
    "               'randomforestclassifier__min_samples_leaf':[1,10], \n",
    "               'randomforestclassifier__min_weight_fraction_leaf':[0.0],\n",
    "               'randomforestclassifier__n_jobs':[1]\n",
    "}\n",
    "param_grid_3 =  {'randomforestclassifier__max_depth': [8],\n",
    "               'randomforestclassifier__criterion': ['gini'], \n",
    "               'randomforestclassifier__n_estimators':[10,100], \n",
    "               'randomforestclassifier__max_leaf_nodes':[None], \n",
    "               'randomforestclassifier__min_samples_split':[2],\n",
    "               'randomforestclassifier__min_samples_leaf':[1], \n",
    "               'randomforestclassifier__min_weight_fraction_leaf':[0.0],\n",
    "               'randomforestclassifier__n_jobs':[1]\n",
    "}\n",
    "param_grid_4 =  {'randomforestclassifier__max_depth': [8],\n",
    "               'randomforestclassifier__criterion': ['gini'], \n",
    "               'randomforestclassifier__n_estimators':[2,5], \n",
    "               'randomforestclassifier__max_leaf_nodes':[None], \n",
    "               'randomforestclassifier__min_samples_split':[2],\n",
    "               'randomforestclassifier__min_samples_leaf':[1,4], \n",
    "               'randomforestclassifier__min_weight_fraction_leaf':[0.0],\n",
    "               'randomforestclassifier__n_jobs':[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Grid Search in two datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "call = PipelineTelstra(RandomForestClassifier)\n",
    "gs = grid_search.GridSearchCV(call, param_grid_4, cv=2, n_jobs=1, pre_dispatch='n_jobs') \n",
    "gs = gs.fit(tr_a,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check order of parameters and extract them for the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sco = gs.grid_scores_\n",
    "sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meanv = np.zeros(len(sco))\n",
    "deptv = np.zeros(len(sco),dtype=np.int)\n",
    "estiv = np.zeros(len(sco),dtype=np.int)\n",
    "deptk = [i for i in sco[0].parameters.keys()][5]\n",
    "estik = [i for i in sco[0].parameters.keys()][2]\n",
    "\n",
    "l = 0\n",
    "while l < len(sco):\n",
    "    mean = sco[l].mean_validation_score\n",
    "    par = sco[l].parameters.values()\n",
    "    values = [v for v in par]\n",
    "    meanv[l] = mean\n",
    "    estiv[l] = values[2]\n",
    "    deptv[l] = values[5]\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ma = np.matrix([[meanv[0], meanv[1]], [meanv[2], meanv[3]]], dtype=np.float64)\n",
    "scores = pd.DataFrame(ma,columns=np.unique(estiv),index=np.unique(deptv))\n",
    "ax = sns.heatmap(scores)\n",
    "ax.set_title('parameters evaluation 3 depth vs estimators')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"par_eval_3_depth8_esti10_100.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = call.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The best combination of parameters will be choosen for runing the final prediction with run_predict.py. The results will be written into results.csv and uploaded."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
