{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competiton | BNP Paribas Cardif Claims Management\n",
    "\n",
    ">We need to build a model to efficiently classify BNP Paribas Cardif claims in order to fastly know whether or not additional information is needed or the approval could be accelerated.\n",
    "\n",
    ">In order to build this model we first need to learn from the data (train data) which features could lead to one decission or the other.\n",
    "\n",
    ">Thus, in the current notebook we will set up a protocol for processing claim customers data that will be implemented in the next notebook in a pipeline and automatically use it in model prediction.\n",
    "\n",
    "Go to the official page of the [Kaggle Competition.](https://www.kaggle.com/c/bnp-paribas-cardif-claims-management)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal for this Notebook:\n",
    "* Develope a protocol for processing data in order to learn out of it\n",
    "* Develope new classes and methods (data_modifier.py) and evaluate them to process data\n",
    "* Explore sklearn classes and methods to process our data\n",
    "* Explore how to organize the steps to include them into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series, DataFrame\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import stats\n",
    "from data_modifier import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for giving a try using given train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../../github_data/bnp_paribas_cardif_data/train.csv\")\n",
    "test = pd.read_csv(\"../../../github_data/bnp_paribas_cardif_data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train.target\n",
    "columns = train.columns\n",
    "x_train = train[columns[2:]]\n",
    "x_test = train[columns[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check if Null values and transform them to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NullToNaNTrans fit done.\n",
      "NullToNaNTrans transform done.\n",
      "NullToNaNTrans transform done.\n"
     ]
    }
   ],
   "source": [
    "nton = NulltoNanTrans()\n",
    "nton = nton.fit(x_train)\n",
    "x_tr_ntont = nton.transform(x_train)\n",
    "x_te_ntont = nton.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Process Continous Float Data\n",
    "* Select Continous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSpliterTrans fit done.\n",
      "DataSpliterTrans transform done.\n",
      "DataSpliterTrans transform done.\n"
     ]
    }
   ],
   "source": [
    "dat = DataSpliterTrans(dtype=np.float64)\n",
    "dat = dat.fit(x_tr_ntont)\n",
    "x_tr_datct = dat.transform(x_tr_ntont)\n",
    "x_te_datct = dat.transform(x_te_ntont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Substitute NaN values by the median using Imputer from Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## if nan change nan to median\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "imp = imp.fit(x_tr_datct)\n",
    "x_tr_ntovt = imp.transform(x_tr_datct)\n",
    "x_te_ntovt = imp.transform(x_te_datct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.33573942,  8.72747444,  3.92102575, ...,  2.02428538,\n",
       "         0.63636451,  2.85714374],\n",
       "       [ 1.4695499 ,  7.02380312,  4.20599079, ...,  1.95782501,\n",
       "         1.56013756,  1.58940327],\n",
       "       [ 0.94387691,  5.3100792 ,  4.41096869, ...,  1.12046842,\n",
       "         0.88311753,  1.1764715 ],\n",
       "       ..., \n",
       "       [ 1.4695499 ,  7.02380312,  4.20599079, ...,  2.41760583,\n",
       "         1.56013756,  1.58940327],\n",
       "       [ 1.4695499 ,  7.02380312,  4.20599079, ...,  3.52664991,\n",
       "         1.56013756,  1.58940327],\n",
       "       [ 1.61976313,  7.93297797,  4.6400847 , ...,  1.60449252,\n",
       "         1.78761032,  1.38613767]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr_ntovt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Process Categorical Integer Data\n",
    "* Select data type integers from the data since in this case all are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSpliterTrans fit done.\n",
      "DataSpliterTrans transform done.\n",
      "DataSpliterTrans transform done.\n"
     ]
    }
   ],
   "source": [
    "dat = DataSpliterTrans(dtype=np.int)\n",
    "dat = dat.fit(x_tr_ntont)\n",
    "x_tr_datit = dat.transform(x_tr_ntont)\n",
    "x_te_datit = dat.transform(x_te_ntont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Substitute NaN values by the most frequent using Imputer from Sklearn (despite of not NaN found in first check exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "imp = imp.fit(x_tr_datit)\n",
    "x_tr_ntovt2 = imp.transform(x_tr_datit)\n",
    "x_te_ntovt2 = imp.transform(x_te_datit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform categories into boolean features to easyly learn from them with OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "enc = enc.fit(x_tr_ntovt2)\n",
    "x_tr_catobit = enc.transform(x_tr_ntovt2)\n",
    "x_te_catobit = enc.transform(x_te_ntovt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<114321x18574 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2172099 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr_catobit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Process Categorical Integer Data\n",
    "* Select data type objects from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSpliterTrans fit done.\n",
      "DataSpliterTrans transform done.\n",
      "DataSpliterTrans transform done.\n"
     ]
    }
   ],
   "source": [
    "dat = DataSpliterTrans(dtype=np.object)\n",
    "dat = dat.fit(x_tr_ntont)\n",
    "x_tr_datot = dat.transform(x_tr_ntont)\n",
    "x_te_datot = dat.transform(x_te_ntont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the string categories to integer categories in order to be further processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjtoCatStrtoIntTrans fit done.\n",
      "(114321, 19)\n",
      "ObjtoCatStrtoIntTrans transform done.\n",
      "(114321, 19)\n",
      "ObjtoCatStrtoIntTrans transform done.\n"
     ]
    }
   ],
   "source": [
    "cat = ObjtoCatStrtoIntTrans()\n",
    "cat = cat.fit(x_tr_datot)\n",
    "x_tr_catot = cat.transform(x_tr_datot)\n",
    "x_tr_catot = cat.transform(x_te_datot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Substitute NaN values by the most frequent using Imputer from Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "imp = imp.fit(x_tr_catot)\n",
    "x_tr_ntovt3 = imp.transform(x_tr_catot)\n",
    "x_te_ntovt3 = imp.transform(x_tr_catot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform categories into boolean features to easyly learn from them with OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "enc = enc.fit(x_tr_ntovt3)\n",
    "x_tr_catobit = enc.transform(x_tr_ntovt3)\n",
    "x_te_catobit = enc.transform(x_te_ntovt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<114321x18574 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2172099 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr_catobit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have generated three matrices with the different data types that need to be processed in a different way and in the next notebook (cv_roc.ipynb) we will apply them directly in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
