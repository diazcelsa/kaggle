{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competiton | BNP Paribas Cardif Claims Management\n",
    "\n",
    ">We need to build a model to quickly and efficiently classify BNP Paribas Cardif claims. In order to learn from the train dataset we need first to process the data. We will include the steps detailed in the previous notebook (check_input_data.ipynb) and the classes are described in data_modifier.py. \n",
    "\n",
    ">Thus, in the current notebook we will set up a protocol for processing the data and explore possible errors.\n",
    "\n",
    "Go to the official page of the [Kaggle Competition.](https://www.kaggle.com/c/bnp-paribas-cardif-claims-management)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal for this Notebook:\n",
    "* Develope a protocol for processing data to include it into a pipeline\n",
    "* Develope new classes and methods (data_modifier.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series, DataFrame\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import stats\n",
    "from data_modifier import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for giving a try using given train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../../github_data/bnp_paribas_cardif_data/train.csv\")\n",
    "test = pd.read_csv(\"../../../github_data/bnp_paribas_cardif_data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train.target\n",
    "columns = train.columns\n",
    "x_train = train[columns[2:]]\n",
    "x_test = train[columns[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Transform Null to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NullToNaNTrans fit done.\n",
      "NullToNaNTrans transform done.\n",
      "NullToNaNTrans transform done.\n"
     ]
    }
   ],
   "source": [
    "nton = NulltoNanTrans()\n",
    "nton = nton.fit(x_train)\n",
    "x_tr_ntont = nton.transform(x_train)\n",
    "x_te_ntont = nton.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Process Continous Float Data\n",
    "* Select Continous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSpliterTrans fit done.\n",
      "DataSpliterTrans transform done.\n",
      "DataSpliterTrans transform done.\n"
     ]
    }
   ],
   "source": [
    "dat = DataSpliterTrans(dtype=np.float64)\n",
    "dat = dat.fit(x_tr_ntont)\n",
    "x_tr_datct = dat.transform(x_tr_ntont)\n",
    "x_te_datct = dat.transform(x_te_ntont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Substitute NaN values by the median using Imputer from Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## if nan change nan to median\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "imp = imp.fit(x_tr_datct)\n",
    "x_tr_ntovt = imp.transform(x_tr_datct)\n",
    "x_te_ntovt = imp.transform(x_te_datct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.33573942,  8.72747444,  3.92102575, ...,  2.02428538,\n",
       "         0.63636451,  2.85714374],\n",
       "       [ 1.4695499 ,  7.02380312,  4.20599079, ...,  1.95782501,\n",
       "         1.56013756,  1.58940327],\n",
       "       [ 0.94387691,  5.3100792 ,  4.41096869, ...,  1.12046842,\n",
       "         0.88311753,  1.1764715 ],\n",
       "       ..., \n",
       "       [ 1.4695499 ,  7.02380312,  4.20599079, ...,  2.41760583,\n",
       "         1.56013756,  1.58940327],\n",
       "       [ 1.4695499 ,  7.02380312,  4.20599079, ...,  3.52664991,\n",
       "         1.56013756,  1.58940327],\n",
       "       [ 1.61976313,  7.93297797,  4.6400847 , ...,  1.60449252,\n",
       "         1.78761032,  1.38613767]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr_ntovt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The continous data is already processed and given as a matrix and will be merge with the next two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Process Categorical Integer Data\n",
    "* Select data type integers from the data since in this case all are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSpliterTrans fit done.\n",
      "DataSpliterTrans transform done.\n",
      "DataSpliterTrans transform done.\n"
     ]
    }
   ],
   "source": [
    "dat = DataSpliterTrans(dtype=np.int)\n",
    "dat = dat.fit(x_tr_ntont)\n",
    "x_tr_datit = dat.transform(x_tr_ntont)\n",
    "x_te_datit = dat.transform(x_te_ntont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Substitute NaN values by the most frequent using Imputer from Sklearn (despite of not NaN found in first check exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "imp = imp.fit(x_tr_datit)\n",
    "x_tr_ntovt2 = imp.transform(x_tr_datit)\n",
    "x_te_ntovt2 = imp.transform(x_te_datit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform categories into boolean features to easyly learn from them with OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "enc = enc.fit(x_tr_ntovt2)\n",
    "x_tr_catobit = enc.transform(x_tr_ntovt2)\n",
    "x_te_catobit = enc.transform(x_te_ntovt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<114321x43 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 457284 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr_catobit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integer categorical data is already processed and given as a matrix and will be merge with the other two. The matrix contain final 43 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Process Categorical Integer Data\n",
    "* Select data type objects from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSpliterTrans fit done.\n",
      "DataSpliterTrans transform done.\n",
      "DataSpliterTrans transform done.\n"
     ]
    }
   ],
   "source": [
    "dat = DataSpliterTrans(dtype=np.object)\n",
    "dat = dat.fit(x_tr_ntont)\n",
    "x_tr_datot = dat.transform(x_tr_ntont)\n",
    "x_te_datot = dat.transform(x_te_ntont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the string categories to integer categories through the new class created in data_modifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjtoCatStrtoIntTrans fit done.\n",
      "(114321, 19)\n",
      "ObjtoCatStrtoIntTrans transform done.\n",
      "(114321, 19)\n",
      "ObjtoCatStrtoIntTrans transform done.\n"
     ]
    }
   ],
   "source": [
    "cat = ObjtoCatStrtoIntTrans()\n",
    "cat = cat.fit(x_tr_datot)\n",
    "x_tr_catot = cat.transform(x_tr_datot)\n",
    "x_tr_catot = cat.transform(x_te_datot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Substitute NaN values by the most frequent using Imputer from Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "imp = imp.fit(x_tr_catot)\n",
    "x_tr_ntovt3 = imp.transform(x_tr_catot)\n",
    "x_te_ntovt3 = imp.transform(x_tr_catot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform categories into boolean features to easyly learn from them with OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "enc = enc.fit(x_tr_ntovt3)\n",
    "x_tr_catobit = enc.transform(x_tr_ntovt3)\n",
    "x_te_catobit = enc.transform(x_te_ntovt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<114321x18574 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2172099 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr_catobit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string categorical data is already processed and given as a matrix and will be merge with the other two. The matrix contain final 18574 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have three matrices with the processed data and all methods are working fine, we will build a pipeline in data_modifier.py that will perform all this steps automatically.\n",
    "\n",
    "In the next notebook (cv_roc.ipynb) we will apply the pipeline, perform the first prediction and evaluate it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
