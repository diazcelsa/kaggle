{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################\n",
    "################   Clean Data + Structure Data + Generate Model + Evaluate\n",
    "################   BNP Paribas Cardif Claims Management Kaggle Competition\n",
    "################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series, DataFrame\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import grid_search\n",
    "from scipy import stats\n",
    "\n",
    "# import other methods\n",
    "from data_modifier import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "##### upload data\n",
    "train = pd.read_csv(\"../../../github_data/bnp_paribas_cardif_data/train.csv\")\n",
    "test = pd.read_csv(\"../../../github_data/bnp_paribas_cardif_data/test.csv\")\n",
    "sample = pd.read_csv(\"../../../github_data/bnp_paribas_cardif_data/sample_submission.csv\")\n",
    "trains = train[:100]\n",
    "tests = test[:100]\n",
    "\n",
    "\n",
    "##### split data  \n",
    "tr_a, te_a = train_test_split(trains, train_size = 0.8)\n",
    "\n",
    "## define variables \n",
    "y_train = tr_a.target\n",
    "y_test = te_a.target\n",
    "columns = train.columns\n",
    "x_train = tr_a[columns[2:]]\n",
    "x_test = te_a[columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define parameters\n",
    "param_grid_1 =  {'randomforestclassifier__max_depth': [8,16],\n",
    "               'randomforestclassifier__criterion': ['gini'], \n",
    "               'randomforestclassifier__n_estimators':[20,100], \n",
    "               'randomforestclassifier__max_leaf_nodes':[None], \n",
    "               'randomforestclassifier__min_samples_split':[2],\n",
    "               'randomforestclassifier__min_samples_leaf':[10], \n",
    "               'randomforestclassifier__min_weight_fraction_leaf':[0.0],\n",
    "               'randomforestclassifier__n_jobs':[1]\n",
    "}\n",
    "param_grid_2 =  {'randomforestclassifier__max_depth': [16,300],\n",
    "               'randomforestclassifier__criterion': ['gini'], \n",
    "               'randomforestclassifier__n_estimators':[5,10], \n",
    "               'randomforestclassifier__max_leaf_nodes':[None], \n",
    "               'randomforestclassifier__min_samples_split':[2],\n",
    "               'randomforestclassifier__min_samples_leaf':[10], \n",
    "               'randomforestclassifier__min_weight_fraction_leaf':[0.0],\n",
    "               'randomforestclassifier__n_jobs':[1]\n",
    "}\n",
    "param_grid_3 =  {'randomforestclassifier__max_depth': [16,75],\n",
    "               'randomforestclassifier__criterion': ['gini'], \n",
    "               'randomforestclassifier__n_estimators':[2,5], \n",
    "               'randomforestclassifier__max_leaf_nodes':[None], \n",
    "               'randomforestclassifier__min_samples_split':[2],\n",
    "               'randomforestclassifier__min_samples_leaf':[10], \n",
    "               'randomforestclassifier__min_weight_fraction_leaf':[0.0],\n",
    "               'randomforestclassifier__n_jobs':[1]\n",
    "}\n",
    "param_grid_4 =  {'randomforestclassifier__max_depth': [8,16],\n",
    "               'randomforestclassifier__criterion': ['gini'], \n",
    "               'randomforestclassifier__n_estimators':[10], \n",
    "               'randomforestclassifier__max_leaf_nodes':[None], \n",
    "               'randomforestclassifier__min_samples_split':[2],\n",
    "               'randomforestclassifier__min_samples_leaf':[1,5], \n",
    "               'randomforestclassifier__min_weight_fraction_leaf':[0.0],\n",
    "               'randomforestclassifier__n_jobs':[1]\n",
    "}\n",
    "param_grid_5 =  {'randomforestclassifier__max_depth': [16,25],\n",
    "               'randomforestclassifier__criterion': ['gini'], \n",
    "               'randomforestclassifier__n_estimators':[10,50], \n",
    "               'randomforestclassifier__max_leaf_nodes':[None], \n",
    "               'randomforestclassifier__min_samples_split':[2],\n",
    "               'randomforestclassifier__min_samples_leaf':[1], \n",
    "               'randomforestclassifier__min_weight_fraction_leaf':[0.0],\n",
    "               'randomforestclassifier__n_jobs':[1]\n",
    "}\n",
    "param_grid_6 =  {'randomforestclassifier__max_depth': [25,40],\n",
    "               'randomforestclassifier__criterion': ['gini'], \n",
    "               'randomforestclassifier__n_estimators':[5,10], \n",
    "               'randomforestclassifier__max_leaf_nodes':[None], \n",
    "               'randomforestclassifier__min_samples_split':[2],\n",
    "               'randomforestclassifier__min_samples_leaf':[1], \n",
    "               'randomforestclassifier__min_weight_fraction_leaf':[0.0],\n",
    "               'randomforestclassifier__n_jobs':[1]\n",
    "}\n",
    "param_grid_7 =  {'randomforestclassifier__max_depth': [40,55],\n",
    "               'randomforestclassifier__criterion': ['gini'], \n",
    "               'randomforestclassifier__n_estimators':[5,10], \n",
    "               'randomforestclassifier__max_leaf_nodes':[None], \n",
    "               'randomforestclassifier__min_samples_split':[2],\n",
    "               'randomforestclassifier__min_samples_leaf':[1], \n",
    "               'randomforestclassifier__min_weight_fraction_leaf':[0.0],\n",
    "               'randomforestclassifier__n_jobs':[1]\n",
    "}\n",
    "param_grid_8 =  {'randomforestclassifier__max_depth': [None],\n",
    "               'randomforestclassifier__criterion': ['gini'], \n",
    "               'randomforestclassifier__n_estimators':[2,5], \n",
    "               'randomforestclassifier__max_leaf_nodes':[None], \n",
    "               'randomforestclassifier__min_samples_split':[2],\n",
    "               'randomforestclassifier__min_samples_leaf':[1], \n",
    "               'randomforestclassifier__min_weight_fraction_leaf':[0.0],\n",
    "               'randomforestclassifier__n_jobs':[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline done.\n",
      "NullToNaNTrans fit done.\n",
      "NullToNaNTrans transform done.\n",
      "DataSpliterTrans fit done.\n",
      "transpose (108, 39)\n",
      "DataSpliterTrans transform done.\n",
      "NullToNaNTrans fit done.\n",
      "NullToNaNTrans transform done.\n",
      "DataSpliterTrans fit done.\n",
      "transpose (4, 39)\n",
      "DataSpliterTrans transform done.\n",
      "DataSpliterTrans fit done.\n",
      "transpose (108, 41)\n",
      "DataSpliterTrans transform done.\n",
      "DataSpliterTrans fit done.\n",
      "transpose (19, 39)\n",
      "DataSpliterTrans transform done.\n",
      "DataSpliterTrans fit done.\n",
      "transpose (4, 41)\n",
      "DataSpliterTrans transform done.\n",
      "DataSpliterTrans fit done.\n",
      "transpose (19, 41)\n",
      "DataSpliterTrans transform done.\n",
      "ObjtoCatStrtoIntTrans fit done.\n",
      "(19, 39)\n",
      "ObjtoCatStrtoIntTrans fit done.\n",
      "ObjtoCatStrtoIntTrans transform done.\n",
      "(19, 41)\n",
      "ObjtoCatStrtoIntTrans transform done.\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.4/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    165         sys.exit(msg)\n    166     main_globals = sys.modules[\"__main__\"].__dict__\n    167     if alter_argv:\n    168         sys.argv[0] = mod_spec.origin\n    169     return _run_code(code, main_globals, None,\n--> 170                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.4/site-packages/ipykernel/__main__.py')\n    171 \n    172 def run_module(mod_name, init_globals=None,\n    173                run_name=None, alter_sys=False):\n    174     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.4/runpy.py in _run_code(code=<code object <module> at 0x7f6d8171bd20, file \"/...3.4/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/celsa/.local/lib/python3.4/site-packages/ipykernel/__pycache__/__main__.cpython-34.pyc', '__doc__': None, '__file__': '/home/celsa/.local/lib/python3.4/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.4/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/home/celsa/.../python3.4/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.4/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f6d8171bd20, file \"/...3.4/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/celsa/.local/lib/python3.4/site-packages/ipykernel/__pycache__/__main__.cpython-34.pyc', '__doc__': None, '__file__': '/home/celsa/.local/lib/python3.4/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.4/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/home/celsa/.../python3.4/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-04-11T14:44:47.862779', 'msg_id': '451C7FEDE89C451EA516CF58AFE4932C', 'msg_type': 'execute_request', 'session': '544407F2905B47258503D0AB87402764', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '451C7FEDE89C451EA516CF58AFE4932C', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'544407F2905B47258503D0AB87402764']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-04-11T14:44:47.862779', 'msg_id': '451C7FEDE89C451EA516CF58AFE4932C', 'msg_type': 'execute_request', 'session': '544407F2905B47258503D0AB87402764', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '451C7FEDE89C451EA516CF58AFE4932C', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'544407F2905B47258503D0AB87402764'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-04-11T14:44:47.862779', 'msg_id': '451C7FEDE89C451EA516CF58AFE4932C', 'msg_type': 'execute_request', 'session': '544407F2905B47258503D0AB87402764', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '451C7FEDE89C451EA516CF58AFE4932C', 'msg_type': 'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\"\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>], cell_name='<ipython-input-6-eefc5e780b80>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f6d5082edb0, file \"<ipython-input-6-eefc5e780b80>\", line 5>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f6d5082edb0, file \"<ipython-input-6-eefc5e780b80>\", line 5>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f6d5082edb0, file \"<ipython-input-6-eefc5e780b80>\", line 5>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame': <class 'pandas.core.frame.DataFrame'>, 'DataSpliterTrans': <class 'data_modifier.DataSpliterTrans'>, 'Debugger': <class 'data_modifier.Debugger'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '################\\n################   Clean Data +...in = tr_a[columns[2:]]\\nx_test = te_a[columns[2:]]', \"## define parameters\\nparam_grid_1 =  {'randomfor...           'randomforestclassifier__n_jobs':[1]\\n}\", \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", '################\\n################   Clean Data +...in = tr_a[columns[2:]]\\nx_test = te_a[columns[2:]]', \"## define parameters\\nparam_grid_1 =  {'randomfor...           'randomforestclassifier__n_jobs':[1]\\n}\", \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\"], 'KFold': <class 'sklearn.cross_validation.KFold'>, 'NulltoNanTrans': <class 'data_modifier.NulltoNanTrans'>, 'ObjtoCatStrtoIntTrans': <class 'data_modifier.ObjtoCatStrtoIntTrans'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame': <class 'pandas.core.frame.DataFrame'>, 'DataSpliterTrans': <class 'data_modifier.DataSpliterTrans'>, 'Debugger': <class 'data_modifier.Debugger'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '################\\n################   Clean Data +...in = tr_a[columns[2:]]\\nx_test = te_a[columns[2:]]', \"## define parameters\\nparam_grid_1 =  {'randomfor...           'randomforestclassifier__n_jobs':[1]\\n}\", \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", '################\\n################   Clean Data +...in = tr_a[columns[2:]]\\nx_test = te_a[columns[2:]]', \"## define parameters\\nparam_grid_1 =  {'randomfor...           'randomforestclassifier__n_jobs':[1]\\n}\", \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\"], 'KFold': <class 'sklearn.cross_validation.KFold'>, 'NulltoNanTrans': <class 'data_modifier.NulltoNanTrans'>, 'ObjtoCatStrtoIntTrans': <class 'data_modifier.ObjtoCatStrtoIntTrans'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/home/celsa/Documents/github/kaggle/bnp_paribas_cardif/<ipython-input-6-eefc5e780b80> in <module>()\n      1 \n      2 ##### generate pipeline \n      3 ## X.shape (91456, 108)\n      4 call = PipelineBNP(RandomForestClassifier)\n----> 5 gs = grid_search.GridSearchCV(call, param_grid_8, cv=2, scoring='roc_auc', n_jobs=2, pre_dispatch='n_jobs')\n      6 gs = gs.fit(x_train,y_train)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=2, error_score='raise',\n       e..._jobs', refit=True, scoring='roc_auc', verbose=0), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], y=61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64)\n    799         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    800             Target relative to X for classification or regression;\n    801             None for unsupervised learning.\n    802 \n    803         \"\"\"\n--> 804         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...jobs', refit=True, scoring='roc_auc', verbose=0)>\n        X =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns]\n        y = 61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64\n        self.param_grid = {'randomforestclassifier__criterion': ['gini'], 'randomforestclassifier__max_depth': [None], 'randomforestclassifier__max_leaf_nodes': [None], 'randomforestclassifier__min_samples_leaf': [1], 'randomforestclassifier__min_samples_split': [2], 'randomforestclassifier__min_weight_fraction_leaf': [0.0], 'randomforestclassifier__n_estimators': [2, 5], 'randomforestclassifier__n_jobs': [1]}\n    805 \n    806 \n    807 class RandomizedSearchCV(BaseSearchCV):\n    808     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=2, error_score='raise',\n       e..._jobs', refit=True, scoring='roc_auc', verbose=0), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], y=61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    548         )(\n    549             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    550                                     train, test, self.verbose, parameters,\n    551                                     self.fit_params, return_parameters=True,\n    552                                     error_score=self.error_score)\n--> 553                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    554                 for train, test in cv)\n    555 \n    556         # Out is a list of triplet: score, estimator, n_test_samples\n    557         n_fits = len(out)\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object <genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Apr 11 14:44:48 2016\nPID: 21529                                  Python 3.4.3+: /usr/bin/python3\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]),           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], 61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5..., 70, 71, 72, 73, 74,\n       75, 76, 77, 78, 79]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 41]), 0, {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__n_jobs': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]),           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], 61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5..., 70, 71, 72, 73, 74,\n       75, 76, 77, 78, 79]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 41]), 0, {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__n_jobs': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], y=61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5..., 70, 71, 72, 73, 74,\n       75, 76, 77, 78, 79]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 41]), verbose=0, parameters={'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__n_jobs': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1526 \n   1527     try:\n   1528         if y_train is None:\n   1529             estimator.fit(X_train, **fit_params)\n   1530         else:\n-> 1531             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...one, verbose=0,\n            warm_start=False))])>\n        X_train =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns]\n        y_train = 41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64\n        fit_params = {}\n   1532 \n   1533     except Exception as e:\n   1534         if error_score == 'raise':\n   1535             raise\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns], y=41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64, **fit_params={})\n    159             pipeline.\n    160         y : iterable, default=None\n    161             Training targets. Must fulfill label requirements for all steps of\n    162             the pipeline.\n    163         \"\"\"\n--> 164         Xt, fit_params = self._pre_transform(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._pre_transform = <bound method Pipeline._pre_transform of Pipelin...one, verbose=0,\n            warm_start=False))])>\n        X =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns]\n        y = 41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64\n    165         self.steps[-1][-1].fit(Xt, y, **fit_params)\n    166         return self\n    167 \n    168     def fit_transform(self, X, y=None, **fit_params):\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py in _pre_transform(self=Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns], y=41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64, **fit_params={})\n    140             step, param = pname.split('__', 1)\n    141             fit_params_steps[step][param] = pval\n    142         Xt = X\n    143         for name, transform in self.steps[:-1]:\n    144             if hasattr(transform, \"fit_transform\"):\n--> 145                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns]\n        transform.fit_transform = <bound method FeatureUnion.fit_transform of Feat...rse=True))]))],\n       transformer_weights=None)>\n        y = 41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64\n        fit_params_steps = {'featureunion': {}, 'nulltonantrans': {}, 'randomforestclassifier': {}}\n        name = 'featureunion'\n    146             else:\n    147                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    148                               .transform(Xt)\n    149         return Xt, fit_params_steps[self.steps[-1][0]]\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[...arse=True))]))],\n       transformer_weights=None), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns], y=41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64, **fit_params={})\n    497             for name, trans in self.transformer_list)\n    498 \n    499         Xs, transformers = zip(*result)\n    500         self._update_transformer_list(transformers)\n    501         if any(sparse.issparse(f) for f in Xs):\n--> 502             Xs = sparse.hstack(Xs).tocsr()\n        Xs = (array([[  7.24113326,   1.35586236,   0.62289606...6.38585383,\n          0.88888808,   0.83623735]]), <4x79 sparse matrix of type '<class 'numpy.float... stored elements in Compressed Sparse Row format>, <19x413 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n        Xs.tocsr = undefined\n    503         else:\n    504             Xs = np.hstack(Xs)\n    505         return Xs\n    506 \n\n...........................................................................\n/usr/lib/python3/dist-packages/scipy/sparse/construct.py in hstack(blocks=(array([[  7.24113326,   1.35586236,   0.62289606...6.38585383,\n          0.88888808,   0.83623735]]), <4x79 sparse matrix of type '<class 'numpy.float... stored elements in Compressed Sparse Row format>, <19x413 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>), format=None, dtype=None)\n    448     >>> hstack( [A,B] ).todense()\n    449     matrix([[1, 2, 5],\n    450             [3, 4, 6]])\n    451 \n    452     \"\"\"\n--> 453     return bmat([blocks], format=format, dtype=dtype)\n        blocks = (array([[  7.24113326,   1.35586236,   0.62289606...6.38585383,\n          0.88888808,   0.83623735]]), <4x79 sparse matrix of type '<class 'numpy.float... stored elements in Compressed Sparse Row format>, <19x413 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n        format = None\n        dtype = None\n    454 \n    455 \n    456 def vstack(blocks, format=None, dtype=None):\n    457     \"\"\"\n\n...........................................................................\n/usr/lib/python3/dist-packages/scipy/sparse/construct.py in bmat(blocks=array([[ <108x39 sparse matrix of type '<class '...in Compressed Sparse Row format>]], dtype=object), format=None, dtype=None)\n    562 \n    563                 if brow_lengths[i] == 0:\n    564                     brow_lengths[i] = A.shape[0]\n    565                 else:\n    566                     if brow_lengths[i] != A.shape[0]:\n--> 567                         raise ValueError('blocks[%d,:] has incompatible row dimensions' % i)\n        i = 0\n    568 \n    569                 if bcol_lengths[j] == 0:\n    570                     bcol_lengths[j] = A.shape[1]\n    571                 else:\n\nValueError: blocks[0,:] has incompatible row dimensions\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\", line 130, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\", line 72, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\", line 72, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/celsa/.local/lib/python3.4/site-packages/sklearn/cross_validation.py\", line 1531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py\", line 164, in fit\n    Xt, fit_params = self._pre_transform(X, y, **fit_params)\n  File \"/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py\", line 145, in _pre_transform\n    Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n  File \"/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py\", line 502, in fit_transform\n    Xs = sparse.hstack(Xs).tocsr()\n  File \"/usr/lib/python3/dist-packages/scipy/sparse/construct.py\", line 453, in hstack\n    return bmat([blocks], format=format, dtype=dtype)\n  File \"/usr/lib/python3/dist-packages/scipy/sparse/construct.py\", line 567, in bmat\n    raise ValueError('blocks[%d,:] has incompatible row dimensions' % i)\nValueError: blocks[0,:] has incompatible row dimensions\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\", line 140, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Apr 11 14:44:48 2016\nPID: 21529                                  Python 3.4.3+: /usr/bin/python3\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]),           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], 61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5..., 70, 71, 72, 73, 74,\n       75, 76, 77, 78, 79]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 41]), 0, {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__n_jobs': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]),           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], 61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5..., 70, 71, 72, 73, 74,\n       75, 76, 77, 78, 79]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 41]), 0, {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__n_jobs': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], y=61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5..., 70, 71, 72, 73, 74,\n       75, 76, 77, 78, 79]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 41]), verbose=0, parameters={'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__n_jobs': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1526 \n   1527     try:\n   1528         if y_train is None:\n   1529             estimator.fit(X_train, **fit_params)\n   1530         else:\n-> 1531             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...one, verbose=0,\n            warm_start=False))])>\n        X_train =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns]\n        y_train = 41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64\n        fit_params = {}\n   1532 \n   1533     except Exception as e:\n   1534         if error_score == 'raise':\n   1535             raise\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns], y=41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64, **fit_params={})\n    159             pipeline.\n    160         y : iterable, default=None\n    161             Training targets. Must fulfill label requirements for all steps of\n    162             the pipeline.\n    163         \"\"\"\n--> 164         Xt, fit_params = self._pre_transform(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._pre_transform = <bound method Pipeline._pre_transform of Pipelin...one, verbose=0,\n            warm_start=False))])>\n        X =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns]\n        y = 41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64\n    165         self.steps[-1][-1].fit(Xt, y, **fit_params)\n    166         return self\n    167 \n    168     def fit_transform(self, X, y=None, **fit_params):\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py in _pre_transform(self=Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns], y=41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64, **fit_params={})\n    140             step, param = pname.split('__', 1)\n    141             fit_params_steps[step][param] = pval\n    142         Xt = X\n    143         for name, transform in self.steps[:-1]:\n    144             if hasattr(transform, \"fit_transform\"):\n--> 145                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns]\n        transform.fit_transform = <bound method FeatureUnion.fit_transform of Feat...rse=True))]))],\n       transformer_weights=None)>\n        y = 41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64\n        fit_params_steps = {'featureunion': {}, 'nulltonantrans': {}, 'randomforestclassifier': {}}\n        name = 'featureunion'\n    146             else:\n    147                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    148                               .transform(Xt)\n    149         return Xt, fit_params_steps[self.steps[-1][0]]\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[...arse=True))]))],\n       transformer_weights=None), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns], y=41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64, **fit_params={})\n    497             for name, trans in self.transformer_list)\n    498 \n    499         Xs, transformers = zip(*result)\n    500         self._update_transformer_list(transformers)\n    501         if any(sparse.issparse(f) for f in Xs):\n--> 502             Xs = sparse.hstack(Xs).tocsr()\n        Xs = (array([[  7.24113326,   1.35586236,   0.62289606...6.38585383,\n          0.88888808,   0.83623735]]), <4x79 sparse matrix of type '<class 'numpy.float... stored elements in Compressed Sparse Row format>, <19x413 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n        Xs.tocsr = undefined\n    503         else:\n    504             Xs = np.hstack(Xs)\n    505         return Xs\n    506 \n\n...........................................................................\n/usr/lib/python3/dist-packages/scipy/sparse/construct.py in hstack(blocks=(array([[  7.24113326,   1.35586236,   0.62289606...6.38585383,\n          0.88888808,   0.83623735]]), <4x79 sparse matrix of type '<class 'numpy.float... stored elements in Compressed Sparse Row format>, <19x413 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>), format=None, dtype=None)\n    448     >>> hstack( [A,B] ).todense()\n    449     matrix([[1, 2, 5],\n    450             [3, 4, 6]])\n    451 \n    452     \"\"\"\n--> 453     return bmat([blocks], format=format, dtype=dtype)\n        blocks = (array([[  7.24113326,   1.35586236,   0.62289606...6.38585383,\n          0.88888808,   0.83623735]]), <4x79 sparse matrix of type '<class 'numpy.float... stored elements in Compressed Sparse Row format>, <19x413 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n        format = None\n        dtype = None\n    454 \n    455 \n    456 def vstack(blocks, format=None, dtype=None):\n    457     \"\"\"\n\n...........................................................................\n/usr/lib/python3/dist-packages/scipy/sparse/construct.py in bmat(blocks=array([[ <108x39 sparse matrix of type '<class '...in Compressed Sparse Row format>]], dtype=object), format=None, dtype=None)\n    562 \n    563                 if brow_lengths[i] == 0:\n    564                     brow_lengths[i] = A.shape[0]\n    565                 else:\n    566                     if brow_lengths[i] != A.shape[0]:\n--> 567                         raise ValueError('blocks[%d,:] has incompatible row dimensions' % i)\n        i = 0\n    568 \n    569                 if bcol_lengths[j] == 0:\n    570                     bcol_lengths[j] = A.shape[1]\n    571                 else:\n\nValueError: blocks[0,:] has incompatible row dimensions\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Apr 11 14:44:48 2016\nPID: 21529                                  Python 3.4.3+: /usr/bin/python3\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]),           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], 61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5..., 70, 71, 72, 73, 74,\n       75, 76, 77, 78, 79]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 41]), 0, {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__n_jobs': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]),           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], 61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5..., 70, 71, 72, 73, 74,\n       75, 76, 77, 78, 79]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 41]), 0, {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__n_jobs': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], y=61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5..., 70, 71, 72, 73, 74,\n       75, 76, 77, 78, 79]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 41]), verbose=0, parameters={'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__n_jobs': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1526 \n   1527     try:\n   1528         if y_train is None:\n   1529             estimator.fit(X_train, **fit_params)\n   1530         else:\n-> 1531             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...one, verbose=0,\n            warm_start=False))])>\n        X_train =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns]\n        y_train = 41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64\n        fit_params = {}\n   1532 \n   1533     except Exception as e:\n   1534         if error_score == 'raise':\n   1535             raise\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns], y=41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64, **fit_params={})\n    159             pipeline.\n    160         y : iterable, default=None\n    161             Training targets. Must fulfill label requirements for all steps of\n    162             the pipeline.\n    163         \"\"\"\n--> 164         Xt, fit_params = self._pre_transform(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._pre_transform = <bound method Pipeline._pre_transform of Pipelin...one, verbose=0,\n            warm_start=False))])>\n        X =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns]\n        y = 41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64\n    165         self.steps[-1][-1].fit(Xt, y, **fit_params)\n    166         return self\n    167 \n    168     def fit_transform(self, X, y=None, **fit_params):\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py in _pre_transform(self=Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns], y=41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64, **fit_params={})\n    140             step, param = pname.split('__', 1)\n    141             fit_params_steps[step][param] = pval\n    142         Xt = X\n    143         for name, transform in self.steps[:-1]:\n    144             if hasattr(transform, \"fit_transform\"):\n--> 145                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns]\n        transform.fit_transform = <bound method FeatureUnion.fit_transform of Feat...rse=True))]))],\n       transformer_weights=None)>\n        y = 41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64\n        fit_params_steps = {'featureunion': {}, 'nulltonantrans': {}, 'randomforestclassifier': {}}\n        name = 'featureunion'\n    146             else:\n    147                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    148                               .transform(Xt)\n    149         return Xt, fit_params_steps[self.steps[-1][0]]\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[...arse=True))]))],\n       transformer_weights=None), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns], y=41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64, **fit_params={})\n    497             for name, trans in self.transformer_list)\n    498 \n    499         Xs, transformers = zip(*result)\n    500         self._update_transformer_list(transformers)\n    501         if any(sparse.issparse(f) for f in Xs):\n--> 502             Xs = sparse.hstack(Xs).tocsr()\n        Xs = (array([[  7.24113326,   1.35586236,   0.62289606...6.38585383,\n          0.88888808,   0.83623735]]), <4x79 sparse matrix of type '<class 'numpy.float... stored elements in Compressed Sparse Row format>, <19x413 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n        Xs.tocsr = undefined\n    503         else:\n    504             Xs = np.hstack(Xs)\n    505         return Xs\n    506 \n\n...........................................................................\n/usr/lib/python3/dist-packages/scipy/sparse/construct.py in hstack(blocks=(array([[  7.24113326,   1.35586236,   0.62289606...6.38585383,\n          0.88888808,   0.83623735]]), <4x79 sparse matrix of type '<class 'numpy.float... stored elements in Compressed Sparse Row format>, <19x413 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>), format=None, dtype=None)\n    448     >>> hstack( [A,B] ).todense()\n    449     matrix([[1, 2, 5],\n    450             [3, 4, 6]])\n    451 \n    452     \"\"\"\n--> 453     return bmat([blocks], format=format, dtype=dtype)\n        blocks = (array([[  7.24113326,   1.35586236,   0.62289606...6.38585383,\n          0.88888808,   0.83623735]]), <4x79 sparse matrix of type '<class 'numpy.float... stored elements in Compressed Sparse Row format>, <19x413 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n        format = None\n        dtype = None\n    454 \n    455 \n    456 def vstack(blocks, format=None, dtype=None):\n    457     \"\"\"\n\n...........................................................................\n/usr/lib/python3/dist-packages/scipy/sparse/construct.py in bmat(blocks=array([[ <108x39 sparse matrix of type '<class '...in Compressed Sparse Row format>]], dtype=object), format=None, dtype=None)\n    562 \n    563                 if brow_lengths[i] == 0:\n    564                     brow_lengths[i] = A.shape[0]\n    565                 else:\n    566                     if brow_lengths[i] != A.shape[0]:\n--> 567                         raise ValueError('blocks[%d,:] has incompatible row dimensions' % i)\n        i = 0\n    568 \n    569                 if bcol_lengths[j] == 0:\n    570                     bcol_lengths[j] = A.shape[1]\n    571                 else:\n\nValueError: blocks[0,:] has incompatible row dimensions\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-eefc5e780b80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipelineBNP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid_8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'n_jobs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/celsa/.local/lib/python3.4/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \"\"\"\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/celsa/.local/lib/python3.4/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 for train, test in cv)\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.4/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    165         sys.exit(msg)\n    166     main_globals = sys.modules[\"__main__\"].__dict__\n    167     if alter_argv:\n    168         sys.argv[0] = mod_spec.origin\n    169     return _run_code(code, main_globals, None,\n--> 170                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.4/site-packages/ipykernel/__main__.py')\n    171 \n    172 def run_module(mod_name, init_globals=None,\n    173                run_name=None, alter_sys=False):\n    174     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.4/runpy.py in _run_code(code=<code object <module> at 0x7f6d8171bd20, file \"/...3.4/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/celsa/.local/lib/python3.4/site-packages/ipykernel/__pycache__/__main__.cpython-34.pyc', '__doc__': None, '__file__': '/home/celsa/.local/lib/python3.4/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.4/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/home/celsa/.../python3.4/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.4/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f6d8171bd20, file \"/...3.4/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/celsa/.local/lib/python3.4/site-packages/ipykernel/__pycache__/__main__.cpython-34.pyc', '__doc__': None, '__file__': '/home/celsa/.local/lib/python3.4/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.4/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/home/celsa/.../python3.4/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-04-11T14:44:47.862779', 'msg_id': '451C7FEDE89C451EA516CF58AFE4932C', 'msg_type': 'execute_request', 'session': '544407F2905B47258503D0AB87402764', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '451C7FEDE89C451EA516CF58AFE4932C', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'544407F2905B47258503D0AB87402764']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-04-11T14:44:47.862779', 'msg_id': '451C7FEDE89C451EA516CF58AFE4932C', 'msg_type': 'execute_request', 'session': '544407F2905B47258503D0AB87402764', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '451C7FEDE89C451EA516CF58AFE4932C', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'544407F2905B47258503D0AB87402764'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-04-11T14:44:47.862779', 'msg_id': '451C7FEDE89C451EA516CF58AFE4932C', 'msg_type': 'execute_request', 'session': '544407F2905B47258503D0AB87402764', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '451C7FEDE89C451EA516CF58AFE4932C', 'msg_type': 'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\"\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>], cell_name='<ipython-input-6-eefc5e780b80>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f6d5082edb0, file \"<ipython-input-6-eefc5e780b80>\", line 5>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f6d5082edb0, file \"<ipython-input-6-eefc5e780b80>\", line 5>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f6d5082edb0, file \"<ipython-input-6-eefc5e780b80>\", line 5>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame': <class 'pandas.core.frame.DataFrame'>, 'DataSpliterTrans': <class 'data_modifier.DataSpliterTrans'>, 'Debugger': <class 'data_modifier.Debugger'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '################\\n################   Clean Data +...in = tr_a[columns[2:]]\\nx_test = te_a[columns[2:]]', \"## define parameters\\nparam_grid_1 =  {'randomfor...           'randomforestclassifier__n_jobs':[1]\\n}\", \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", '################\\n################   Clean Data +...in = tr_a[columns[2:]]\\nx_test = te_a[columns[2:]]', \"## define parameters\\nparam_grid_1 =  {'randomfor...           'randomforestclassifier__n_jobs':[1]\\n}\", \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\"], 'KFold': <class 'sklearn.cross_validation.KFold'>, 'NulltoNanTrans': <class 'data_modifier.NulltoNanTrans'>, 'ObjtoCatStrtoIntTrans': <class 'data_modifier.ObjtoCatStrtoIntTrans'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame': <class 'pandas.core.frame.DataFrame'>, 'DataSpliterTrans': <class 'data_modifier.DataSpliterTrans'>, 'Debugger': <class 'data_modifier.Debugger'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '################\\n################   Clean Data +...in = tr_a[columns[2:]]\\nx_test = te_a[columns[2:]]', \"## define parameters\\nparam_grid_1 =  {'randomfor...           'randomforestclassifier__n_jobs':[1]\\n}\", \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\", '################\\n################   Clean Data +...in = tr_a[columns[2:]]\\nx_test = te_a[columns[2:]]', \"## define parameters\\nparam_grid_1 =  {'randomfor...           'randomforestclassifier__n_jobs':[1]\\n}\", \"##### generate pipeline \\n## X.shape (91456, 108)...e_dispatch='n_jobs')\\ngs = gs.fit(x_train,y_train)\"], 'KFold': <class 'sklearn.cross_validation.KFold'>, 'NulltoNanTrans': <class 'data_modifier.NulltoNanTrans'>, 'ObjtoCatStrtoIntTrans': <class 'data_modifier.ObjtoCatStrtoIntTrans'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/home/celsa/Documents/github/kaggle/bnp_paribas_cardif/<ipython-input-6-eefc5e780b80> in <module>()\n      1 \n      2 ##### generate pipeline \n      3 ## X.shape (91456, 108)\n      4 call = PipelineBNP(RandomForestClassifier)\n----> 5 gs = grid_search.GridSearchCV(call, param_grid_8, cv=2, scoring='roc_auc', n_jobs=2, pre_dispatch='n_jobs')\n      6 gs = gs.fit(x_train,y_train)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=2, error_score='raise',\n       e..._jobs', refit=True, scoring='roc_auc', verbose=0), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], y=61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64)\n    799         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    800             Target relative to X for classification or regression;\n    801             None for unsupervised learning.\n    802 \n    803         \"\"\"\n--> 804         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...jobs', refit=True, scoring='roc_auc', verbose=0)>\n        X =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns]\n        y = 61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64\n        self.param_grid = {'randomforestclassifier__criterion': ['gini'], 'randomforestclassifier__max_depth': [None], 'randomforestclassifier__max_leaf_nodes': [None], 'randomforestclassifier__min_samples_leaf': [1], 'randomforestclassifier__min_samples_split': [2], 'randomforestclassifier__min_weight_fraction_leaf': [0.0], 'randomforestclassifier__n_estimators': [2, 5], 'randomforestclassifier__n_jobs': [1]}\n    805 \n    806 \n    807 class RandomizedSearchCV(BaseSearchCV):\n    808     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=2, error_score='raise',\n       e..._jobs', refit=True, scoring='roc_auc', verbose=0), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], y=61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    548         )(\n    549             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    550                                     train, test, self.verbose, parameters,\n    551                                     self.fit_params, return_parameters=True,\n    552                                     error_score=self.error_score)\n--> 553                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    554                 for train, test in cv)\n    555 \n    556         # Out is a list of triplet: score, estimator, n_test_samples\n    557         n_fits = len(out)\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object <genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Apr 11 14:44:48 2016\nPID: 21529                                  Python 3.4.3+: /usr/bin/python3\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]),           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], 61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5..., 70, 71, 72, 73, 74,\n       75, 76, 77, 78, 79]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 41]), 0, {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__n_jobs': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]),           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], 61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5..., 70, 71, 72, 73, 74,\n       75, 76, 77, 78, 79]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 41]), 0, {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__n_jobs': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[80 rows x 131 columns], y=61    1\n96    0\n97    1\n99    1\n2     1\n86    0\n... 1\n77    1\nName: target, Length: 80, dtype: int64, scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5..., 70, 71, 72, 73, 74,\n       75, 76, 77, 78, 79]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 41]), verbose=0, parameters={'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_leaf_nodes': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__min_weight_fraction_leaf': 0.0, 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__n_jobs': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1526 \n   1527     try:\n   1528         if y_train is None:\n   1529             estimator.fit(X_train, **fit_params)\n   1530         else:\n-> 1531             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...one, verbose=0,\n            warm_start=False))])>\n        X_train =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns]\n        y_train = 41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64\n        fit_params = {}\n   1532 \n   1533     except Exception as e:\n   1534         if error_score == 'raise':\n   1535             raise\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns], y=41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64, **fit_params={})\n    159             pipeline.\n    160         y : iterable, default=None\n    161             Training targets. Must fulfill label requirements for all steps of\n    162             the pipeline.\n    163         \"\"\"\n--> 164         Xt, fit_params = self._pre_transform(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._pre_transform = <bound method Pipeline._pre_transform of Pipelin...one, verbose=0,\n            warm_start=False))])>\n        X =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns]\n        y = 41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64\n    165         self.steps[-1][-1].fit(Xt, y, **fit_params)\n    166         return self\n    167 \n    168     def fit_transform(self, X, y=None, **fit_params):\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py in _pre_transform(self=Pipeline(steps=[('nulltonantrans', NulltoNanTran...None, verbose=0,\n            warm_start=False))]), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns], y=41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64, **fit_params={})\n    140             step, param = pname.split('__', 1)\n    141             fit_params_steps[step][param] = pval\n    142         Xt = X\n    143         for name, transform in self.steps[:-1]:\n    144             if hasattr(transform, \"fit_transform\"):\n--> 145                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt =           v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns]\n        transform.fit_transform = <bound method FeatureUnion.fit_transform of Feat...rse=True))]))],\n       transformer_weights=None)>\n        y = 41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64\n        fit_params_steps = {'featureunion': {}, 'nulltonantrans': {}, 'randomforestclassifier': {}}\n        name = 'featureunion'\n    146             else:\n    147                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    148                               .transform(Xt)\n    149         return Xt, fit_params_steps[self.steps[-1][0]]\n\n...........................................................................\n/home/celsa/.local/lib/python3.4/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[...arse=True))]))],\n       transformer_weights=None), X=          v1         v2   v3        v4         v... 0  8.318840  0.836237  \n\n[39 rows x 131 columns], y=41    0\n90    1\n16    1\n26    1\n54    1\n93    1\n...6    1\n78    1\n77    1\nName: target, dtype: int64, **fit_params={})\n    497             for name, trans in self.transformer_list)\n    498 \n    499         Xs, transformers = zip(*result)\n    500         self._update_transformer_list(transformers)\n    501         if any(sparse.issparse(f) for f in Xs):\n--> 502             Xs = sparse.hstack(Xs).tocsr()\n        Xs = (array([[  7.24113326,   1.35586236,   0.62289606...6.38585383,\n          0.88888808,   0.83623735]]), <4x79 sparse matrix of type '<class 'numpy.float... stored elements in Compressed Sparse Row format>, <19x413 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n        Xs.tocsr = undefined\n    503         else:\n    504             Xs = np.hstack(Xs)\n    505         return Xs\n    506 \n\n...........................................................................\n/usr/lib/python3/dist-packages/scipy/sparse/construct.py in hstack(blocks=(array([[  7.24113326,   1.35586236,   0.62289606...6.38585383,\n          0.88888808,   0.83623735]]), <4x79 sparse matrix of type '<class 'numpy.float... stored elements in Compressed Sparse Row format>, <19x413 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>), format=None, dtype=None)\n    448     >>> hstack( [A,B] ).todense()\n    449     matrix([[1, 2, 5],\n    450             [3, 4, 6]])\n    451 \n    452     \"\"\"\n--> 453     return bmat([blocks], format=format, dtype=dtype)\n        blocks = (array([[  7.24113326,   1.35586236,   0.62289606...6.38585383,\n          0.88888808,   0.83623735]]), <4x79 sparse matrix of type '<class 'numpy.float... stored elements in Compressed Sparse Row format>, <19x413 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n        format = None\n        dtype = None\n    454 \n    455 \n    456 def vstack(blocks, format=None, dtype=None):\n    457     \"\"\"\n\n...........................................................................\n/usr/lib/python3/dist-packages/scipy/sparse/construct.py in bmat(blocks=array([[ <108x39 sparse matrix of type '<class '...in Compressed Sparse Row format>]], dtype=object), format=None, dtype=None)\n    562 \n    563                 if brow_lengths[i] == 0:\n    564                     brow_lengths[i] = A.shape[0]\n    565                 else:\n    566                     if brow_lengths[i] != A.shape[0]:\n--> 567                         raise ValueError('blocks[%d,:] has incompatible row dimensions' % i)\n        i = 0\n    568 \n    569                 if bcol_lengths[j] == 0:\n    570                     bcol_lengths[j] = A.shape[1]\n    571                 else:\n\nValueError: blocks[0,:] has incompatible row dimensions\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "##### generate pipeline \n",
    "## X.shape (91456, 108)\n",
    "call = PipelineBNP(RandomForestClassifier)\n",
    "gs = grid_search.GridSearchCV(call, param_grid_8, cv=2, scoring='roc_auc', n_jobs=2, pre_dispatch='n_jobs')\n",
    "gs = gs.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### plot the roc_auc to compare parameters\n",
    "sco = gs.grid_scores_\n",
    "sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract data from scoring function\n",
    "meanv = np.zeros(len(sco))\n",
    "deptv = np.zeros(len(sco),dtype=np.int)\n",
    "estiv = np.zeros(len(sco),dtype=np.int)\n",
    "deptk = [i for i in sco[0].parameters.keys()][3]\n",
    "estik = [i for i in sco[0].parameters.keys()][1]\n",
    "\n",
    "l = 0\n",
    "while l < len(sco):\n",
    "    mean = sco[l].mean_validation_score\n",
    "    par = sco[l].parameters.values()\n",
    "    values = [v for v in par]\n",
    "    meanv[l] = mean\n",
    "    estiv[l] = values[1]\n",
    "    deptv[l] = values[3]\n",
    "    l += 1\n",
    "print(deptk,estik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot scoring function data\n",
    "ma = np.matrix([[meanv[0], meanv[1]], [meanv[2], meanv[3]]], dtype=np.float64)\n",
    "scores = pd.DataFrame(ma,columns=np.unique(estiv),index=np.unique(deptv))\n",
    "ax = sns.heatmap(scores)\n",
    "ax.set_title('parameters evaluation roc_auc 7 depth vs n_estimators')\n",
    "ax.set_title\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"par_eval_7_depth40_55_esti5_10.png\")\n",
    "print(ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### generate y_predict\n",
    "y_predict = gs.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### check parameters\n",
    "#call.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Compute ROC curve and ROC area for each fold\n",
    "fpr1, tpr1, thresholds1 = metrics.roc_curve(y_test1,y_predict1_1)\n",
    "a1 = metrics.auc(fpr1, tpr1)\n",
    "fpr2, tpr2, thresholds2 = metrics.roc_curve(y_test2,y_predict2_1)\n",
    "a2 = metrics.auc(fpr2, tpr2)\n",
    "fpr3, tpr3, thresholds3 = metrics.roc_curve(y_test3,y_predict3_1)\n",
    "a3 = metrics.auc(fpr3, tpr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.set_style(\"whitegrid\")\n",
    "ax = sns.set_context(\"notebook\", font_scale=1.1, rc={\"lines.linewidth\": 1.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr1, tpr1, label='ROC curve 1 (area = %0.2f)' % a1)\n",
    "plt.plot(fpr2, tpr2, label='ROC curve 2 (area = %0.2f)' % a2)\n",
    "plt.plot(fpr3, tpr3, label='ROC curve 3 (area = %0.2f)' % a3)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for 3-fold CV before Grid Search')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.savefig(\"ROC_Curve_wGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
